{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bcdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from collections import deque\n",
    "import json\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logfiles_path = Path('logfiles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import requests\n",
    "\n",
    "CHAT_MODEL = 'google/gemini-2.0-flash-001'\n",
    "\n",
    "def chat(messages: List[Dict[str, str]]) -> str:\n",
    "    response = requests.post(\n",
    "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY']}\",\n",
    "        },\n",
    "        data=json.dumps({\n",
    "            'model': CHAT_MODEL,\n",
    "            \"messages\": messages,\n",
    "        })\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    reply = response.json()['choices'][0]['message']['content']\n",
    "    return reply\n",
    "    \n",
    "def find_next_unused_file(root: Path, suffix: str) -> Path:\n",
    "    '''of the form [number][suffix]'''\n",
    "    assert root.exists()\n",
    "    # TODO: binary search\n",
    "    for i in range(0, 1000000):\n",
    "        outpath = logfiles_path / f'{i}{suffix}'\n",
    "        if not outpath.exists():\n",
    "            return outpath\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb16d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthesize a bunch of log files. put them in `logfiles`\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional\n",
    "\n",
    "NUM_FILES_TO_GENERATE = 10\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "  def gen_log() -> Optional[str]:\n",
    "    for retry in range(4):\n",
    "      content = chat([\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": '''Generate a plausible log file, as would be emitted from some application or service.\n",
    "It should contain both uninteresting and interesting lines, including interesting lines that aren't clearly marked as that.\n",
    "Include poorly formatted log lines.\n",
    "Reply ONLY with the log lines. No explanations, markdown quotes or any other form of framing.\n",
    "            '''\n",
    "          }\n",
    "        ])\n",
    "      if content.startswith('```') or content.endswith('```'):\n",
    "          print('undesired framing in llm response. retrying')\n",
    "      else:\n",
    "          return content\n",
    "    print('model is stubborn. giving up')\n",
    "    return None\n",
    "  logs = executor.map(lambda _: gen_log(), range(NUM_FILES_TO_GENERATE))\n",
    "  for log in logs:\n",
    "    if log is None:\n",
    "       continue\n",
    "    logfiles_path.mkdir(exist_ok=True, parents=True)\n",
    "    outpath = find_next_unused_file(logfiles_path, '.log')\n",
    "    with outpath.open('w') as f:\n",
    "        f.write(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask the model if the generated files look good.\n",
    "# it isn't very accurate or useful\n",
    "\n",
    "format_check = []\n",
    "for p in logfiles_path.glob('*.log'):\n",
    "    logfile = p.read_text()\n",
    "    def fun(msg: str):\n",
    "      lmsg = msg.lower()\n",
    "      if 'yes' in lmsg:\n",
    "         return True\n",
    "      if 'no' in lmsg:\n",
    "         return False\n",
    "      raise Exception(f'bad reply from model: {msg}')\n",
    "    for retry in range(100000):\n",
    "      try:\n",
    "        response = chat([\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": f\"Does the following text look like a raw log file? It mustn't contain any additional framing, only the actual log lines. Answer ONLY with yes or no:\\n{logfile}\"\n",
    "            }\n",
    "          ]\n",
    "        )\n",
    "        good = fun(response)\n",
    "        break\n",
    "      except Exception as e:\n",
    "        if retry < 10:\n",
    "          print(f'{e}. retrying..')\n",
    "        else:\n",
    "          raise\n",
    "    format_check.append((p, good))\n",
    "    print(f'{p}: {\"good\" if good else \"bad\"}')\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a66a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "system_prompt = {\n",
    "                \"role\": \"system\",\n",
    "                'content': '''You are a developer log analyzer.\n",
    "Given a sequence of log lines. Rate only the last line. Use the prior lines only for context.\n",
    "If a prior line looks unrelated to the last one, disregard it.\n",
    "Rate the last line by how interesting you think it is for diagnosing an issue with the system.\n",
    "Output EXACTLY in this format:\n",
    "```\n",
    "Very brief single-sentence analysis on a single line\n",
    "SCORE: 0-100\n",
    "```\n",
    "\n",
    "Do NOT include any code examples, snippets, or additional explanations.\n",
    "Keep responses strictly limited to the analysis and score.\n",
    "Do NOT include any additional framing such as ````.\n",
    "\n",
    "Score guide:\n",
    "Low (0-30): Routine/minor info\n",
    "Medium (31-70): Noteworthy/important\n",
    "High (71-100): Critical/security issues\n",
    "'''\n",
    "}\n",
    "formatre = re.compile(r'^.*\\nSCORE: (?:100|\\d{1,2})$')\n",
    "\n",
    "def iterate_line_windows():\n",
    "  for log_path in list(logfiles_path.glob('*.log'))[:1]:\n",
    "    history = deque(maxlen=3)\n",
    "    with log_path.open('r') as f:\n",
    "        for line in f.readlines():\n",
    "          line = line.rstrip()\n",
    "          history.append(line)\n",
    "          # TODO: concat a random number of lines to avoid overfitting\n",
    "          lines = ''.join((f'{l}\\n' for l in history))\n",
    "          yield lines\n",
    "\n",
    "def generate_conversations():\n",
    "  for lines in iterate_line_windows():\n",
    "    query = {\n",
    "              'role': 'user',\n",
    "              'content': lines,\n",
    "            }\n",
    "    for retry in range(4):\n",
    "      reply = chat([\n",
    "              system_prompt,\n",
    "              query,\n",
    "            ])\n",
    "      if formatre.match(reply) is None:\n",
    "        print(f'bad reply from model: {reply}')\n",
    "        continue\n",
    "      break\n",
    "    else:\n",
    "      print('the model is obstinate, ignoring this line')\n",
    "      continue\n",
    "    assert isinstance(system_prompt['content'], str)\n",
    "    assert isinstance(lines, str)\n",
    "    assert isinstance(reply, str)\n",
    "    yield {\n",
    "      'conversations': [\n",
    "        system_prompt,\n",
    "        query,\n",
    "        {\n",
    "          'role': 'assistant',\n",
    "          'content': reply\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "\n",
    "dataset_list = list(generate_conversations())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7565c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.Dataset.from_generator(generate_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    hf_dataset = datasets.Dataset.from_generator(executor.map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddcf259",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list2 = [{'conversations': [{'role': 'system', 'content': d['instruction']}, {'role': 'user', 'content': d['input']}, {'role': 'assistant', 'content': d['output']}]} for d in dataset_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = datasets.Dataset.from_list(dataset_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82aa088",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_path = Path('/Users/joel/moushkka@gmail.com - Google Drive/My Drive/colab/llmog_data/dataset3')\n",
    "hf_dataset_path.mkdir(exist_ok=True, parents=True)\n",
    "hf_dataset.save_to_disk(hf_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ea6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_conversations_generator():\n",
    "    \"\"\"Generator function to load and parse conversations from .json.gz files.\"\"\"\n",
    "    for file_path in conversations_root.glob('*.json.gz'):\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            conversations_list = json.load(f)\n",
    "            #assert len(conversations_list) == 1\n",
    "            print(conversations_list)\n",
    "        yield {'conversations': conversations_list }\n",
    "\n",
    "# Create the Hugging Face Dataset using the generator\n",
    "hf_dataset = datasets.Dataset.from_generator(load_conversations_generator)\n",
    "hf_dataset_path = Path('/Users/joel/moushkka@gmail.com - Google Drive/My Drive/colab/llmog_data/dataset')\n",
    "hf_dataset_path.mkdir(exist_ok=True, parents=True)\n",
    "hf_dataset.save_to_disk(hf_dataset_path)\n",
    "\n",
    "# Print the dataset info and the first example\n",
    "print(hf_dataset)\n",
    "if len(hf_dataset) > 0:\n",
    "    print(\"\\nFirst example:\")\n",
    "    print(hf_dataset[0])\n",
    "else:\n",
    "    print(\"\\nDataset is empty. Check warnings/errors during generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fd494",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('conversations/0.json.gz', 'rt', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    print(json.dumps(data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
